# Emotion-detection
# Description:
This Emotion detection project is part of a bigger project which is building an assistant for visually impaired people that can make their lives easier by using image captioning (to describe the scene abstractly) , object detection(to tell the user the place of a specific object they are looking for) , face recognition(to tell the user who is standing in front of them), and emotion detection techniques (to tell the user how is the person in front of them is feeling from the way they look because this part of communication is always missing for the blind people)  then all these outputs are converted to speech as a feedback to the user.

# Model Architecture:
VGG16 model was tried but it didn't give any promising results, and i couldn't try large transfer learning networks like Resnet50 or inception due to the limited resources so i decided to build a model from scratch with the following architecture 


